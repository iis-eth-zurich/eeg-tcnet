{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eeg_tcnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp4Un3jeyBhM",
        "outputId": "8a6f8e91-4f7c-454e-87b1-164e91eb5213"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep  5 19:11:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    61W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv8rQhoQEHOU"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DhIOHYh03iF"
      },
      "source": [
        "# download data\n",
        "!wget http://bnci-horizon-2020.eu/database/data-sets/001-2014/A0{1..9}T.mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHrvKIKr1FSS"
      },
      "source": [
        "!wget http://bnci-horizon-2020.eu/database/data-sets/001-2014/A0{1..9}E.mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDXb_rW5EI-d"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAUqnW5aVV7e"
      },
      "source": [
        "## Import Tensorflow 1.x version (actual 1.15) to use pretrained models provided by the code authors in https://github.com/okbalefthanded/eeg-tcnet/blob/master/Accuracy_and_kappa_scores.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGZAp7AhU0Kc"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCAGV45gX45b"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jza5kwp3CDad"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "# \n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhEriWwjEKZc"
      },
      "source": [
        "# Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk4gSmXjz0m2"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv1D,Conv2D, AveragePooling2D,SeparableConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Add, Lambda,DepthwiseConv2D,Input, Permute\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "\n",
        "def EEGTCNet(nb_classes,Chans=64, Samples=128, layers=3, kernel_s=10,filt=10, dropout=0, activation='relu', F1=4, D=2, kernLength=64, dropout_eeg=0.1):\n",
        "    input1 = Input(shape = (1,Chans, Samples))\n",
        "    input2 = Permute((3,2,1))(input1)\n",
        "    regRate=.25\n",
        "    numFilters = F1\n",
        "    F2= numFilters*D\n",
        "\n",
        "    EEGNet_sep = EEGNet(input_layer=input2,F1=F1,kernLength=kernLength,D=D,Chans=Chans,dropout=dropout_eeg)\n",
        "    block2 = Lambda(lambda x: x[:,:,-1,:])(EEGNet_sep)\n",
        "    outs = TCN_block(input_layer=block2,input_dimension=F2,depth=layers,kernel_size=kernel_s,filters=filt,dropout=dropout,activation=activation)\n",
        "    out = Lambda(lambda x: x[:,-1,:])(outs)\n",
        "    dense        = Dense(nb_classes, name = 'dense',kernel_constraint = max_norm(regRate))(out)\n",
        "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
        "    \n",
        "    return Model(inputs=input1,outputs=softmax, name=\"EEG-TCNET\")\n",
        "\n",
        "def EEGNet(input_layer=None,F1=4, kernLength=64, D=2, Chans=22, Samples=128, dropout=0.1, fullmodel=False, nb_classes=4):\n",
        "    F2= F1*D\n",
        "    norm_rate =.25\n",
        "    if fullmodel:\n",
        "        input1 = Input(shape = (1, Chans, Samples))\n",
        "        input2 = Permute((3,2,1))(input1)\n",
        "        input_layer = input2\n",
        "    \n",
        "    block1 = Conv2D(F1, (kernLength, 1), padding = 'same',data_format='channels_last',use_bias = False)(input_layer)\n",
        "    block1 = BatchNormalization(axis = -1)(block1)\n",
        "    block2 = DepthwiseConv2D((1, Chans), use_bias = False, \n",
        "                                    depth_multiplier = D,\n",
        "                                    data_format='channels_last',\n",
        "                                    depthwise_constraint = max_norm(1.))(block1)\n",
        "    block2 = BatchNormalization(axis = -1)(block2)\n",
        "    block2 = Activation('elu')(block2)\n",
        "    block2 = AveragePooling2D((8,1),data_format='channels_last')(block2)\n",
        "    block2 = Dropout(dropout)(block2)\n",
        "    block3 = SeparableConv2D(F2, (16, 1),\n",
        "                            data_format='channels_last',\n",
        "                            use_bias = False, padding = 'same')(block2)\n",
        "    block3 = BatchNormalization(axis = -1)(block3)\n",
        "    block3 = Activation('elu')(block3)\n",
        "    block3 = AveragePooling2D((8,1),data_format='channels_last')(block3)\n",
        "    block3 = Dropout(dropout)(block3)    \n",
        "\n",
        "    if fullmodel:\n",
        "        flatten = Flatten(name = 'flatten')(block3)    \n",
        "        dense  = Dense(nb_classes, name = 'dense', kernel_constraint = max_norm(norm_rate))(flatten)\n",
        "        softmax = Activation('softmax', name = 'softmax')(dense)\n",
        "        return Model(inputs=input1, outputs=softmax, name=\"EEGNet\")\n",
        "    else:\n",
        "        return block3\n",
        "\n",
        "def TCN_block(input_layer,input_dimension,depth,kernel_size,filters,dropout,activation='relu'):\n",
        "    block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=1,activation='linear',\n",
        "                   padding = 'causal',kernel_initializer='he_uniform')(input_layer)\n",
        "    block = BatchNormalization()(block)\n",
        "    block = Activation(activation)(block)\n",
        "    block = Dropout(dropout)(block)\n",
        "    block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=1,activation='linear',\n",
        "                   padding = 'causal',kernel_initializer='he_uniform')(block)\n",
        "    block = BatchNormalization()(block)\n",
        "    block = Activation(activation)(block)\n",
        "    block = Dropout(dropout)(block)\n",
        "    if(input_dimension != filters):\n",
        "        conv = Conv1D(filters,kernel_size=1,padding='same')(input_layer)\n",
        "        added = Add()([block,conv])\n",
        "    else:\n",
        "        added = Add()([block,input_layer])\n",
        "    out = Activation(activation)(added)\n",
        "    \n",
        "    for i in range(depth-1):\n",
        "        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',\n",
        "                   padding = 'causal',kernel_initializer='he_uniform')(out)\n",
        "        block = BatchNormalization()(block)\n",
        "        block = Activation(activation)(block)\n",
        "        block = Dropout(dropout)(block)\n",
        "        block = Conv1D(filters,kernel_size=kernel_size,dilation_rate=2**(i+1),activation='linear',\n",
        "                   padding = 'causal',kernel_initializer='he_uniform')(block)\n",
        "        block = BatchNormalization()(block)\n",
        "        block = Activation(activation)(block)\n",
        "        block = Dropout(dropout)(block)\n",
        "        added = Add()([block, out])\n",
        "        out = Activation(activation)(added)\n",
        "        \n",
        "    return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjilxBlyEMuV"
      },
      "source": [
        "# Preprocessing utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne_G_9C40IjT"
      },
      "source": [
        "import scipy.io as sio\n",
        "import glob as glob\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def load_all_data (crossValidation, data_path): \n",
        "\n",
        "    big_X_train, big_y_train, big_X_test, big_y_test = [None]*9, [None]*9, [None]*9, [None]*9\n",
        "    for subject in range (0,9):\n",
        "        # path = data_path+'s' + str(subject+1) + '/'\n",
        "        path = data_path\n",
        "        big_X_train[subject], big_y_train[subject] = get_data(subject+1, True ,path)\n",
        "        big_X_test[subject], big_y_test[subject] = get_data(subject+1, False ,path)\n",
        "    \n",
        "    return big_X_train, big_y_train, big_X_test, big_y_test\n",
        "\n",
        "def get_data(subject,training,path, highpass = False):\n",
        "\t'''\tLoads the dataset 2a of the BCI Competition IV\n",
        "\tavailable on http://bnci-horizon-2020.eu/database/data-sets\n",
        "\tKeyword arguments:\n",
        "\tsubject -- number of subject in [1, .. ,9]\n",
        "\ttraining -- if True, load training data\n",
        "\t\t\t\tif False, load testing data\n",
        "\t\n",
        "\tReturn:\tdata_return \tnumpy matrix \tsize = NO_valid_trial x 22 x 1750\n",
        "\t\t\tclass_return \tnumpy matrix \tsize = NO_valid_trial\n",
        "\t'''\n",
        "\tNO_channels = 22\n",
        "\tNO_tests = 6*48 \t\n",
        "\tWindow_Length = 7*250 \n",
        "\n",
        "\tclass_return = np.zeros(NO_tests)\n",
        "\tdata_return = np.zeros((NO_tests,NO_channels,Window_Length))\n",
        "\n",
        "\tNO_valid_trial = 0\n",
        "\tif training:\n",
        "\t\ta = sio.loadmat(path+'A0'+str(subject)+'T.mat')\n",
        "\telse:\n",
        "\t\ta = sio.loadmat(path+'A0'+str(subject)+'E.mat')\n",
        "\ta_data = a['data']\n",
        "\tfor ii in range(0,a_data.size):\n",
        "\t\ta_data1 = a_data[0,ii]\n",
        "\t\ta_data2= [a_data1[0,0]]\n",
        "\t\ta_data3= a_data2[0]\n",
        "\t\ta_X \t\t= a_data3[0]\n",
        "\t\ta_trial \t= a_data3[1]\n",
        "\t\ta_y \t\t= a_data3[2]\n",
        "\t\ta_fs \t\t= a_data3[3]\n",
        "\t\ta_classes \t= a_data3[4]\n",
        "\t\ta_artifacts = a_data3[5]\n",
        "\t\ta_gender \t= a_data3[6]\n",
        "\t\ta_age \t\t= a_data3[7]\n",
        "\n",
        "\t\tfor trial in range(0,a_trial.size):\n",
        "\t\t\tif(a_artifacts[trial]==0):\n",
        "\t\t\t\tdata_return[NO_valid_trial,:,:] = np.transpose(a_X[int(a_trial[trial]):(int(a_trial[trial])+Window_Length),:22])\n",
        "\t\t\t\tclass_return[NO_valid_trial] = int(a_y[trial])\n",
        "\t\t\t\tNO_valid_trial +=1\n",
        "\n",
        "\treturn data_return[0:NO_valid_trial,:,:], class_return[0:NO_valid_trial]\n",
        "\n",
        "def prepare_features(path, subject, crossValidation=False):\n",
        "    fs = 250 \n",
        "    t1 = int(1.5*fs)\n",
        "    t2 = int(6*fs)\n",
        "    T = t2-t1\n",
        "    X_train, y_train = get_data(subject+1,True,path)\n",
        "    if crossValidation:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=0)\n",
        "    else:\n",
        "        X_test, y_test = get_data(subject+1,False , path)\n",
        "\n",
        "    # prepare training data \t\n",
        "    N_tr,N_ch,_ =X_train.shape \n",
        "    X_train = X_train[:,:,t1:t2].reshape(N_tr,1,N_ch,T)\n",
        "    y_train_onehot = (y_train-1).astype(int)\n",
        "    y_train_onehot = to_categorical(y_train_onehot)\n",
        "    # prepare testing data \n",
        "    N_test, N_ch,_ =X_test.shape \n",
        "    X_test = X_test[:,:,t1:t2].reshape(N_test,1,N_ch,T)\n",
        "    y_test_onehot = (y_test-1).astype(int)\n",
        "    y_test_onehot = to_categorical(y_test_onehot)\t\n",
        "\n",
        "    return X_train,y_train,y_train_onehot,X_test,y_test,y_test_onehot"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hFi3iySEO-h"
      },
      "source": [
        "# Evaluate dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7LEMAedOAGM"
      },
      "source": [
        "# from utils.models import EEGTCNet\n",
        "# from utils.data_loading import prepare_features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "F1 = 8\n",
        "KE = 32\n",
        "KT = 4\n",
        "L = 2\n",
        "FT = 12\n",
        "pe = 0.2\n",
        "pt = 0.3\n",
        "classes = 4\n",
        "\n",
        "channels = 22\n",
        "crossValidation = False\n",
        "batch_size = 64\n",
        "epochs = 750\n",
        "lr = 0.001\n",
        "\n",
        "def evaluate_model(model):\n",
        "    accs = []\n",
        "    ks = []\n",
        "    for subject in range(9):\n",
        "        # path = data_path+'s{:}/'.format(subject+1)\n",
        "        print(f\"Evaluating subject: {subject+1}\")\n",
        "        path = data_path\n",
        "        X_train, y_train, y_train_onehot, X_test, y_test, y_test_onehot = prepare_features(path, subject, crossValidation)   \n",
        "    \n",
        "        opt = Adam(lr=lr)\n",
        "        model.compile(loss=categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "        for j in range(22):\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(X_train[:,0,j,:])\n",
        "            X_train[:,0,j,:] = scaler.transform(X_train[:,0,j,:])\n",
        "            X_test[:,0,j,:] = scaler.transform(X_test[:,0,j,:])\n",
        "\n",
        "        model.fit(X_train, y_train_onehot, batch_size=batch_size, epochs=750, verbose=0)\n",
        "        y_pred = model.predict(X_test).argmax(axis=-1)\n",
        "        labels = y_test_onehot.argmax(axis=-1)\n",
        "        accuracy_of_test = accuracy_score(labels, y_pred)\n",
        "        kappa = cohen_kappa_score(labels, y_pred)\n",
        "        accs.append(accuracy_of_test)\n",
        "        ks.append(kappa)\n",
        "        print(f\"Model : {model.name} Subject: {subject+1} Acc: {accuracy_of_test} Kappa: {kappa}\")\n",
        "\n",
        "    print(f\"Model : {model.name} Mean accuracy for all dataset: {np.mean(accs)} std. {np.std(accs)}\")\n",
        "    print(f\"Model : {model.name} Mean Kappa for all dataset: {np.mean(ks)} std. {np.std(ks)}\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXiCbZPYWSy5",
        "outputId": "57271b79-55e8-4dda-9f33-55712a2c105b"
      },
      "source": [
        "model = EEGTCNet(nb_classes = 4,Chans=22, Samples=1125, layers=L, kernel_s=KT,\n",
        "                     filt=FT, dropout=pt, activation='elu', F1=F1, D=2, \n",
        "                     kernLength=KE, dropout_eeg=pe)\n",
        "evaluate_model(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating subject: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 1 Acc: 0.8042704626334519 Kappa: 0.7389931265093814\n",
            "Evaluating subject: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 2 Acc: 0.5441696113074205 Kappa: 0.39221855958445706\n",
            "Evaluating subject: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 3 Acc: 0.9084249084249084 Kappa: 0.877837044461946\n",
            "Evaluating subject: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 4 Acc: 0.7192982456140351 Kappa: 0.6248071582844801\n",
            "Evaluating subject: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 5 Acc: 0.6340579710144928 Kappa: 0.5126488225318625\n",
            "Evaluating subject: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 6 Acc: 0.586046511627907 Kappa: 0.44797045841387073\n",
            "Evaluating subject: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 7 Acc: 0.8700361010830325 Kappa: 0.8268629765955969\n",
            "Evaluating subject: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 8 Acc: 0.7822878228782287 Kappa: 0.7094493912411413\n",
            "Evaluating subject: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEG-TCNET Subject: 9 Acc: 0.8295454545454546 Kappa: 0.7725706409372847\n",
            "Model : EEG-TCNET Mean accuracy for all dataset: 0.7420152321254369 std. 0.12150931447444091\n",
            "Model : EEG-TCNET Mean Kappa for all dataset: 0.6559286865066689 std. 0.161973484809704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LHkoRXdCWsS",
        "outputId": "b8ea6102-7805-4be6-fec2-87305302fe73"
      },
      "source": [
        "model = EEGNet(F1=F1, kernLength=KE, D=2, Chans=22, Samples=1125, dropout=pt, fullmodel=True)\n",
        "evaluate_model(model)   "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating subject: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 1 Acc: 0.8220640569395018 Kappa: 0.7628331729714218\n",
            "Evaluating subject: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 2 Acc: 0.568904593639576 Kappa: 0.4260207474398191\n",
            "Evaluating subject: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 3 Acc: 0.8754578754578755 Kappa: 0.8338197117536479\n",
            "Evaluating subject: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 4 Acc: 0.6754385964912281 Kappa: 0.5688218757986199\n",
            "Evaluating subject: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 5 Acc: 0.7101449275362319 Kappa: 0.6144039677272886\n",
            "Evaluating subject: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 6 Acc: 0.6093023255813953 Kappa: 0.47899838449111465\n",
            "Evaluating subject: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 7 Acc: 0.776173285198556 Kappa: 0.7025374556161774\n",
            "Evaluating subject: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 8 Acc: 0.7859778597785978 Kappa: 0.7145814418013438\n",
            "Evaluating subject: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model : EEGNet Subject: 9 Acc: 0.7803030303030303 Kappa: 0.7069810165339865\n",
            "Model : EEGNet Mean accuracy for all dataset: 0.7337518389917769 std. 0.09498176115880937\n",
            "Model : EEGNet Mean Kappa for all dataset: 0.6454441971259355 std. 0.12639322232753367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtEacDi3SgsZ"
      },
      "source": [
        "# Pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbwV9F_0Sibx",
        "outputId": "0d5e7535-9665-4e8b-8810-3bde65b46e20"
      },
      "source": [
        "# dowload code\n",
        "!git clone https://github.com/iis-eth-zurich/eeg-tcnet.git"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eeg-tcnet'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 61 (delta 16), reused 61 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj3b-Gs_TUkR"
      },
      "source": [
        "## Accuracy and Kappa score calculation for EEG-TCNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwoHTRzmT70E"
      },
      "source": [
        "from joblib import dump, load\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(path):\n",
        "    model = load_model(path)\n",
        "    #model = load_model(path +'best.h5')\n",
        "    for l in model.layers:\n",
        "        l.trainable = False\n",
        "    lr = 0.001\n",
        "    model.compile(loss = 'categorical_crossentropy',optimizer=Adam(lr=lr),metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "class Scaler( BaseEstimator, TransformerMixin ):\n",
        "    #Class Constructor \n",
        "    def __init__( self ):\n",
        "        self.scalers = {}\n",
        "        for j in range(22):\n",
        "            self.scalers[j] = StandardScaler()\n",
        "    \n",
        "    #Return self nothing else to do here    \n",
        "    def fit( self, X, y = None ):\n",
        "        for j in range(22):\n",
        "            self.scalers[j].fit(X[:,0 ,j, :])\n",
        "        return self \n",
        "    \n",
        "    #Method that describes what we need this transformer to do\n",
        "    def transform( self, X, y = None ):\n",
        "        for j in range(22):\n",
        "            X[:,0,j,:] = self.scalers[j].transform(X[:,0 ,j, :])\n",
        "        return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfyJ3tp-SoyM",
        "outputId": "eb957f33-fd3b-493d-c3ab-ab74c887206d"
      },
      "source": [
        "for i in range(9):\n",
        "    clf = load('eeg-tcnet/models/EEG-TCNet/S{:}/pipeline_fixed.h5'.format(i+1)) \n",
        "    data_path = '/content/'\n",
        "    path = data_path\n",
        "    X_train,_,y_train_onehot,X_test,_,y_test_onehot = prepare_features(path,i,False)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    acc_score = accuracy_score(y_pred,np.argmax(y_test_onehot,axis=1))\n",
        "    kappa_score = cohen_kappa_score(y_pred,np.argmax(y_test_onehot,axis=1))\n",
        "    print('For Subject: {:}, Accuracy: {:}, Kappa: {:}.'.format(i+1,acc_score*100, kappa_score))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 1, Accuracy: 85.76512455516014, Kappa: 0.8101928467695633.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 2, Accuracy: 65.01766784452296, Kappa: 0.5339432753888381.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 3, Accuracy: 94.5054945054945, Kappa: 0.926729767932867.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 4, Accuracy: 64.91228070175438, Kappa: 0.5318755774561132.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 5, Accuracy: 75.36231884057972, Kappa: 0.671779087459121.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 6, Accuracy: 61.395348837209305, Kappa: 0.4850076476869354.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 7, Accuracy: 87.36462093862815, Kappa: 0.8317628889235948.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 8, Accuracy: 83.76383763837639, Kappa: 0.7835188177411448.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 9, Accuracy: 78.03030303030303, Kappa: 0.7066441872940455.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELSgDldPTbJu"
      },
      "source": [
        "## Accuracy and Kappa score calculation for Variable EEG-TCNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qomehl_WTbvK",
        "outputId": "19caa0fc-9d05-4e74-8965-b862f37a03fe"
      },
      "source": [
        "for i in range(9):\n",
        "    clf = load('eeg-tcnet/models/EEG-TCNet/S{:}/pipeline.h5'.format(i+1)) \n",
        "    data_path = '/content/'\n",
        "    path = data_path\n",
        "    X_train,_,y_train_onehot,X_test,_,y_test_onehot = prepare_features(path,i,False)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    acc_score = accuracy_score(y_pred,np.argmax(y_test_onehot,axis=1))\n",
        "    kappa_score = cohen_kappa_score(y_pred,np.argmax(y_test_onehot,axis=1))\n",
        "    print('For Subject: {:}, Accuracy: {:}, Kappa: {:}.'.format(i+1,acc_score*100, kappa_score))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 1, Accuracy: 89.32384341637011, Kappa: 0.8576302100925488.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 2, Accuracy: 72.43816254416961, Kappa: 0.6325715331990611.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 3, Accuracy: 97.43589743589743, Kappa: 0.9658072250353379.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 4, Accuracy: 75.87719298245614, Kappa: 0.6782800554158757.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 5, Accuracy: 83.69565217391305, Kappa: 0.7826885727783319.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 6, Accuracy: 70.69767441860465, Kappa: 0.6094853683148335.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 7, Accuracy: 93.14079422382672, Kappa: 0.9085903848825899.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 8, Accuracy: 86.71586715867159, Kappa: 0.822837219437786.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Subject: 9, Accuracy: 85.22727272727273, Kappa: 0.8029247377689304.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqmSJ3_ZVLYb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}